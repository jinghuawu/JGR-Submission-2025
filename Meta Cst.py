import os
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import pandas as pd
import numpy as np
import joblib
import threading
import sys  # æ·»åŠ å¯¼å…¥sys
from PIL import Image, ImageTk
import torch
from pytorch_tabnet.tab_model import TabNetClassifier
from tkinterdnd2 import DND_FILES, TkinterDnD
from PIL import Image, ImageTk, ImageDraw
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.ensemble import RandomForestRegressor

# å…¨å±€é¢œè‰²æ–¹æ¡ˆ - é«˜çº§ç§‘æŠ€æ„Ÿé…è‰²
COLORS = {
    "background": "#7e779d",
    "card": "#9d96be",
    "accent": "#F2A7C7",
    "text": "#FFFFFF",
    "text_muted": "#FFFFFF",
    "success": "#a1bae7",
    "button": "#a1bae7",
    "grey": "#484554",
    "button_hover": "#7e779d"
}

class ModelPredictorApp:
    def __init__(self):
        # åˆ›å»ºä¸»çª—å£å¹¶æ”¯æŒæ‹–æ”¾
        self.root = TkinterDnD.Tk()
        self.root.title("Meta Cassiterite_1.0")
        self.root.geometry("1200x900")
        self.root.tk.call('tk', 'scaling', 1.5)  # é€‚åº”é«˜æ¸…æ˜¾ç¤ºå™¨
        self.root.configure(bg=COLORS["background"])

        # è®¾ç½®åº”ç”¨çŠ¶æ€å’Œæ•°æ®
        self.models = {
            "Random Forest": None,
            "XGBoost": None,
            "TabNet": None,
            "Stacking": None
        }
        self.models_loaded = False  # è·Ÿè¸ªæ¨¡å‹æ˜¯å¦å·²åŠ è½½
        self.data = None
        self.processed_data = None
        self.prediction_results = None
        self.feature_names = None
        self.sample_ids = None

        # å…ƒç´ ç‰¹å¾åˆ—è¡¨
        self.element_features = ['Al', 'Sc', 'Ti', 'V', 'Fe', 'Ga', 'W', 'Sb', 'Zr', 'Hf', 'Nb', 'Ta', 'U']
        # æ´¾ç”Ÿç‰¹å¾åˆ—è¡¨
        self.derived_features = ['ZrHf', 'NbTa', 'SbW', 'FeAl', 'UHf', 'UZr']

        # åˆ›å»ºç•Œé¢å¸ƒå±€
        self.create_layout()

        # åˆ›å»ºåŠ è½½é®ç½©ï¼ˆåˆå§‹éšè—ï¼‰
        self.create_loading_overlay()

    def resource_path(self, relative_path):
        """ è·å–èµ„æºçš„ç»å¯¹è·¯å¾„ """
        try:
            # PyInstaller åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹å¹¶å°†è·¯å¾„å­˜å‚¨åœ¨ _MEIPASS ä¸­
            base_path = sys._MEIPASS
        except Exception:
            base_path = os.path.abspath(".")
        
        return os.path.join(base_path, relative_path)

    def create_layout(self):
        """åˆ›å»ºä¸»ç•Œé¢å¸ƒå±€"""
        # é¡¶éƒ¨æ ‡é¢˜æ 
        header = tk.Frame(self.root, bg=COLORS["background"], height=60)
        header.pack(fill=tk.X)

        title_label = tk.Label(header, text="Meta Cassiterite",
                              font=("Arial", 30, "bold"),
                              fg="#2b2848", bg=COLORS["background"])
        # ä½¿ç”¨ place() ç²¾ç¡®å±…ä¸­
        title_label.place(relx=0.5, rely=0.5, anchor="center")

        # ä¸»ç•Œé¢åˆ†ä¸ºå·¦å³ä¸¤æ 
        main_frame = tk.Frame(self.root, bg=COLORS["background"])
        main_frame.pack(fill=tk.BOTH, expand=True, padx=15, pady=15)

        # å·¦ä¾§æ§åˆ¶é¢æ¿
        left_frame = tk.Frame(main_frame, bg=COLORS["card"], width=300)
        left_frame.pack(side=tk.LEFT, fill=tk.Y, padx=10, pady=10)

        # ä¸Šä¼ åŒºåŸŸ
        upload_label = tk.Label(left_frame, text="ğŸ’ Upload",
                               font=("Arial", 20, "bold"),
                               fg=COLORS["text"], bg=COLORS["card"])
        upload_label.pack(anchor=tk.W, padx=50, pady=(15, 10))

        # æ‹–æ”¾åŒºåŸŸ
        self.drop_area = tk.Frame(left_frame, bg=COLORS["text"],
                                 height=150, width=270)
        self.drop_area.pack(fill=tk.X, padx=12, pady=10)
        self.drop_area.pack_propagate(False)

        self.drop_text = tk.Label(self.drop_area,
                                 text="Drop file here (xls, csv, xlsx)\n or \nClick to upload",
                                 font=("Arial", 12, "bold"),
                                 fg=COLORS["grey"], bg=COLORS["text"])
        self.drop_text.pack(expand=True)

        # æ³¨å†Œæ‹–æ”¾åŒºåŸŸ
        self.drop_area.drop_target_register(DND_FILES)
        self.drop_area.dnd_bind('<<Drop>>', self.on_drop)

        # æµè§ˆæŒ‰é’®
        browse_btn = tk.Button(left_frame, text="Open file", bg=COLORS["button"],
                              fg=COLORS["text"], font=("Arial", 15, "bold"),
                              relief=tk.FLAT, padx=10, pady=5,
                              command=self.browse_file)
        browse_btn.pack(fill=tk.X, padx=15, pady=10)

        # æ–‡ä»¶ä¿¡æ¯æ˜¾ç¤º
        self.file_var = tk.StringVar(value="No File Selected")
        file_info = tk.Label(left_frame, textvariable=self.file_var,
                            fg=COLORS["text_muted"], bg=COLORS["card"],
                            font=("Arial", 15, "bold"), wraplength=270)
        file_info.pack(fill=tk.X, padx=15, pady=5)

        # åˆ†éš”çº¿
        separator = ttk.Separator(left_frame, orient="horizontal")
        separator.pack(fill=tk.X, padx=15, pady=15)

        # æ¨¡å‹æ§åˆ¶
        model_label = tk.Label(left_frame, text="ğŸ’ Process",
                              font=("Arial", 20, "bold"),
                              fg=COLORS["text"], bg=COLORS["card"])
        model_label.pack(anchor=tk.W, padx=50, pady=(5, 10))

        # é¢„æµ‹æŒ‰é’®
        predict_btn = tk.Button(left_frame, text="Prediction", bg=COLORS["success"],
                               fg=COLORS["text"], font=("Arial", 15, "bold"),
                               relief=tk.FLAT, padx=10, pady=8,
                               command=self.run_prediction)
        predict_btn.pack(fill=tk.X, padx=15, pady=10)

        # å¯¼å‡ºæŒ‰é’®
        export_btn = tk.Button(left_frame, text="Export Results", bg=COLORS["accent"],
                              fg=COLORS["text"], font=("Arial", 15, "bold"),
                              relief=tk.FLAT, padx=10, pady=5,
                              command=self.export_results)
        export_btn.pack(fill=tk.X, padx=15, pady=5)

        # æ·»åŠ å¯¼å‡ºå¤„ç†åæ•°æ®é›†æŒ‰é’®
        export_processed_btn = tk.Button(left_frame, text="Export Processed Data",
                                        bg=COLORS["grey"],
                                        fg=COLORS["text"], font=("Arial", 15, "bold"),
                                        relief=tk.FLAT, padx=10, pady=5,
                                        command=self.export_processed_data)
        export_processed_btn.pack(fill=tk.X, padx=15, pady=5)

        # æ¨¡å‹çŠ¶æ€æŒ‡ç¤º
        self.status_var = tk.StringVar(value="Ready")
        status_label = tk.Label(left_frame, textvariable=self.status_var,
                               font=("Arial", 10, "bold"),
                               fg=COLORS["text_muted"], bg=COLORS["card"])
        status_label.pack(anchor=tk.W, padx=15, pady=(20, 5))

        # å³ä¾§ç»“æœæ˜¾ç¤ºé¢æ¿
        right_frame = tk.Frame(main_frame, bg=COLORS["background"])
        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)

        # ç»“æœæ ‡é¢˜
        results_label = tk.Label(right_frame, text="Results",
                                font=("Arial", 20, "bold"),
                                fg=COLORS["text"], bg=COLORS["background"])
        results_label.pack(anchor=tk.W, padx=350, pady=10)

        # ç»“æœè¡¨æ ¼æ¡†æ¶
        table_frame = tk.Frame(right_frame, bg=COLORS["card"])
        table_frame.pack(fill=tk.BOTH, expand=True, padx=30, pady=10)

        # åˆ›å»ºæ»šåŠ¨æ¡
        y_scroll = ttk.Scrollbar(table_frame)
        y_scroll.pack(side=tk.RIGHT, fill=tk.Y)

        x_scroll = ttk.Scrollbar(table_frame, orient=tk.HORIZONTAL)
        x_scroll.pack(side=tk.BOTTOM, fill=tk.X)

        # åˆ›å»ºç»“æœæ˜¾ç¤ºçš„æ ‘å½¢è§†å›¾
        self.result_tree = ttk.Treeview(table_frame,
                                       yscrollcommand=y_scroll.set,
                                       xscrollcommand=x_scroll.set)
        self.result_tree.pack(fill=tk.BOTH, expand=True)

        # é…ç½®æ»šåŠ¨æ¡
        y_scroll.config(command=self.result_tree.yview)
        x_scroll.config(command=self.result_tree.xview)

        # è®¾ç½®æ ‘å½¢è§†å›¾æ ·å¼
        style = ttk.Style()
        style.configure("Treeview",
                       background=COLORS["card"],
                       foreground=COLORS["text"],
                       fieldbackground=COLORS["card"],
                       borderwidth=0)
        style.configure("Treeview.Heading",
                       background=COLORS["background"],
                       foreground=COLORS["accent"],
                       font=("Arial", 10, "bold"))

        # åº•éƒ¨çŠ¶æ€æ 
        self.status_bar = tk.Label(self.root, text="Ready",
                                  font=("Arial", 10, "bold"),
                                  bg="#7e779d", fg=COLORS["text_muted"],
                                  anchor=tk.W, padx=15)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

    def create_loading_overlay(self):
        """åˆ›å»ºåŠ è½½é®ç½©"""
        self.loading_frame = tk.Frame(self.root, bg=COLORS["background"])
        self.loading_frame.place(x=0, y=0, relwidth=1, relheight=1)

        loading_text = tk.Label(self.loading_frame, text="In processing, please wait...",
                               font=("Arial", 16, "bold"),
                               fg=COLORS["accent"], bg=COLORS["background"])
        loading_text.place(relx=0.5, rely=0.4, anchor=tk.CENTER)

        progress = ttk.Progressbar(self.loading_frame, mode="indeterminate",
                                  length=400)
        progress.place(relx=0.5, rely=0.5, anchor=tk.CENTER)
        progress.start()

        # åˆå§‹éšè—
        self.loading_frame.place_forget()

    def on_drop(self, event):
        """å¤„ç†æ–‡ä»¶æ‹–æ”¾"""
        file_path = event.data

        # å¤„ç†Windowsè·¯å¾„æ ¼å¼
        if file_path.startswith("{") and file_path.endswith("}"):
            file_path = file_path[1:-1]
        if file_path.startswith('"') and file_path.endswith('"'):
            file_path = file_path[1:-1]

        # å¤šæ–‡ä»¶åªå–ç¬¬ä¸€ä¸ª
        if " " in file_path:
            file_path = file_path.split(" ")[0]

        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if file_path.lower().endswith(('.csv', '.xlsx', '.xls')):
            self.load_data(file_path)
        else:
            messagebox.showerror("Error", "Unsupported file format. Please upload a CSV or Excel file.")

    def browse_file(self):
        """é€šè¿‡æ–‡ä»¶å¯¹è¯æ¡†é€‰æ‹©æ–‡ä»¶"""
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©æ•°æ®æ–‡ä»¶",
            filetypes=[
                ("All files", "*.*"),
                ("Excel file", "*.xlsx *.xls"),
                ("CSV file", "*.csv")
            ]
        )

        if file_path:
            self.load_data(file_path)

    def apply_log10_transform(self, df):
        """å¯¹å…ƒç´ ç‰¹å¾è¿›è¡ŒLog10å˜æ¢ï¼Œä¿ç•™ç¼ºå¤±å€¼"""
        transformed_df = df.copy()
        for col in self.element_features:
            if col in transformed_df.columns:
                # ä»…å¯¹éç¼ºå¤±å€¼åº”ç”¨log10å˜æ¢
                mask = transformed_df[col].notna() & (transformed_df[col] > 0)
                transformed_df.loc[mask, col] = np.log10(transformed_df.loc[mask, col])
        return transformed_df

    def impute_missing_values(self, df):
        """ä½¿ç”¨éšæœºæ£®æ—å¤šæ¬¡æ’è¡¥ç¼ºå¤±å€¼å¹¶å¹³å‡"""
        # æå–è¦æ’è¡¥çš„åˆ—
        cols_to_impute = [col for col in self.element_features if col in df.columns]
        if not cols_to_impute:
            return df

        # æå–éœ€è¦æ’è¡¥çš„æ•°æ®
        data_to_impute = df[cols_to_impute].copy()

        # å¦‚æœæ²¡æœ‰ç¼ºå¤±å€¼ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
        if not data_to_impute.isna().any().any():
            return df

        # å¤šé‡æ’è¡¥
        imputed_data_list = []
        for i in range(10):  # æ‰§è¡Œ10æ¬¡æ’è¡¥
            estimator = RandomForestRegressor(
                n_estimators=50,
                max_depth=7,
                n_jobs=-1,
                random_state=2025+i
            )

            imp = IterativeImputer(
                estimator=estimator,
                max_iter=15,
                random_state=2025+i,
                tol=0.01
            )

            # æ‰§è¡Œæ’è¡¥
            imputed_data = imp.fit_transform(data_to_impute)
            imputed_data_list.append(imputed_data)

        # è®¡ç®—å¹³å‡å€¼
        imputed_avg = np.mean(imputed_data_list, axis=0)

        # åˆ›å»ºæ’è¡¥åçš„DataFrame
        imputed_df = df.copy()
        imputed_df[cols_to_impute] = imputed_avg

        return imputed_df

    def create_derived_features(self, df):
        """åˆ›å»ºæ´¾ç”Ÿç‰¹å¾"""
        df_with_derived = df.copy()

        # ç¡®ä¿æ‰€æœ‰å…ƒç´ ç‰¹å¾éƒ½å­˜åœ¨
        for col in self.element_features:
            if col not in df_with_derived.columns:
                self.status_bar.config(text=f"Warning: {col} column not found. Derived features may be incomplete.")

        # åˆ›å»ºæ´¾ç”Ÿç‰¹å¾
        if 'Zr' in df.columns and 'Hf' in df.columns:
            df_with_derived['ZrHf'] = df['Zr'] - df['Hf']

        if 'Nb' in df.columns and 'Ta' in df.columns:
            df_with_derived['NbTa'] = df['Nb'] - df['Ta']

        if 'Sb' in df.columns and 'W' in df.columns:
            df_with_derived['SbW'] = df['Sb'] - df['W']

        if 'Fe' in df.columns and 'Al' in df.columns:
            df_with_derived['FeAl'] = df['Fe'] - df['Al']

        if 'U' in df.columns and 'Hf' in df.columns:
            df_with_derived['UHf'] = df['U'] - df['Hf']

        if 'U' in df.columns and 'Zr' in df.columns:
            df_with_derived['UZr'] = df['U'] - df['Zr']

        return df_with_derived

    def load_data(self, file_path):
        """åŠ è½½å¹¶å¤„ç†æ•°æ®æ–‡ä»¶"""
        try:
            # æ˜¾ç¤ºåŠ è½½é®ç½©
            self.loading_frame.place(x=0, y=0, relwidth=1, relheight=1)
            self.root.update_idletasks()

            # æ ¹æ®æ–‡ä»¶ç±»å‹åŠ è½½æ•°æ®
            if file_path.lower().endswith('.csv'):
                self.data = pd.read_csv(file_path)
            else:  # Excelæ–‡ä»¶
                self.data = pd.read_excel(file_path)

            # å¤åˆ¶åŸå§‹æ•°æ®ç”¨äºä¿ç•™æ‰€æœ‰åˆ—
            self.original_data = self.data.copy()

            # æ£€æŸ¥æ•°æ®æ ¼å¼
            # æå–IDåˆ—ï¼Œå¦‚æœå­˜åœ¨çš„è¯
            self.sample_id_column = None
            self.sample_ids = None

            # æ£€æŸ¥å¯èƒ½çš„IDåˆ—å
            possible_id_columns = ['ID', 'Sample_ID', 'SampleID', 'Sample', 'id', 'sample_id', 'sampleid', 'sample']
            for col in possible_id_columns:
                if col in self.data.columns:
                    self.sample_id_column = col
                    self.sample_ids = self.data[col].astype(str).tolist()  # ç¡®ä¿è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    break

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°IDåˆ—ï¼Œç”Ÿæˆé»˜è®¤ID
            if self.sample_ids is None:
                self.sample_ids = [f"æ ·å“{i+1}" for i in range(len(self.data))]
                # æ·»åŠ åˆ°åŸå§‹æ•°æ®ä¸­
                self.original_data['Sample_ID'] = self.sample_ids
                self.sample_id_column = 'Sample_ID'

            # æ˜¾ç¤ºåŸå§‹æ•°æ®ä¸­å…ƒç´ ç‰¹å¾çš„ç¼ºå¤±å€¼ç»Ÿè®¡
            print("\nåŸå§‹æ•°æ®ç¼ºå¤±å€¼ç»Ÿè®¡:")
            for col in self.element_features:
                if col in self.data.columns:
                    missing = self.data[col].isna().sum()
                    total = len(self.data)
                    print(f"{col}: {missing}/{total} ({missing/total*100:.1f}%)")

            # 1. å¯¹å…ƒç´ ç‰¹å¾è¿›è¡ŒLog10å˜æ¢
            self.status_bar.config(text="Applying LOG10 transform...")
            log10_data = self.apply_log10_transform(self.data)
            print("\nLOG10å˜æ¢åçš„æ•°æ®æ ·ä¾‹ï¼š")
            element_cols_in_data = [col for col in self.element_features if col in log10_data.columns]
            if element_cols_in_data:
                print(log10_data[element_cols_in_data].head())

            # æ˜¾ç¤ºLOG10å˜æ¢åç¼ºå¤±å€¼ç»Ÿè®¡
            print("\nLOG10å˜æ¢åç¼ºå¤±å€¼ç»Ÿè®¡:")
            for col in self.element_features:
                if col in log10_data.columns:
                    missing = log10_data[col].isna().sum()
                    total = len(log10_data)
                    print(f"{col}: {missing}/{total} ({missing/total*100:.1f}%)")

            # 2. å¯¹Log10å˜æ¢åçš„æ•°æ®è¿›è¡Œç¼ºå¤±å€¼æ’è¡¥
            self.status_bar.config(text="Imputing missing values with Random Forest...")
            imputed_data = self.impute_missing_values(log10_data)
            print("\néšæœºæ£®æ—æ’è¡¥åçš„æ•°æ®æ ·ä¾‹ï¼š")
            if element_cols_in_data:
                print(imputed_data[element_cols_in_data].head())

            # æ˜¾ç¤ºæ’è¡¥åç¼ºå¤±å€¼ç»Ÿè®¡
            print("\néšæœºæ£®æ—æ’è¡¥åç¼ºå¤±å€¼ç»Ÿè®¡:")
            for col in self.element_features:
                if col in imputed_data.columns:
                    missing = imputed_data[col].isna().sum()
                    total = len(imputed_data)
                    print(f"{col}: {missing}/{total} ({missing/total*100:.1f}%)")

            # 3. åˆ›å»ºæ´¾ç”Ÿç‰¹å¾
            self.status_bar.config(text="Creating derived features...")
            processed_data = self.create_derived_features(imputed_data)
            print("\næ´¾ç”Ÿç‰¹å¾è®¡ç®—åçš„æ•°æ®æ ·ä¾‹ï¼š")
            derived_cols_in_data = [col for col in self.derived_features if col in processed_data.columns]
            if derived_cols_in_data:
                print(processed_data[derived_cols_in_data].head())

            # å¤„ç†é¢„æµ‹ç‰¹å¾
            self.processed_df = processed_data.copy()  # ä¿å­˜å¤„ç†åçš„å®Œæ•´DataFrame
            X = processed_data.copy()

            # å¦‚æœæ‰¾åˆ°äº†IDåˆ—ï¼Œä»ç‰¹å¾ä¸­ç§»é™¤
            if self.sample_id_column and self.sample_id_column in X.columns:
                X = X.drop(columns=[self.sample_id_column])

            # å¦‚æœæœ‰Groupåˆ—ï¼Œä¹Ÿéœ€è¦åˆ é™¤
            if 'Group' in X.columns:
                X = X.drop(columns=['Group'])

            # æ›´æ–°ç‰¹å¾ååˆ—è¡¨
            self.feature_names = X.columns.tolist()
            self.processed_data = X.values

            # æ›´æ–°æ–‡ä»¶ä¿¡æ¯
            self.file_var.set(f"Loading data: {os.path.basename(file_path)}\n{len(self.data)} Row Ã— {len(self.feature_names)} Column")
            self.status_bar.config(text=f"Data has been loaded and processed successfully: {os.path.basename(file_path)}")

            # æ˜¾ç¤ºå¤„ç†æµç¨‹æ‘˜è¦
            print("\næ•°æ®å¤„ç†æµç¨‹æ‘˜è¦:")
            print(f"åŸå§‹æ•°æ®: {len(self.data)} è¡Œ Ã— {len(self.data.columns)} åˆ—")
            print(f"å¤„ç†åæ•°æ®: {len(self.processed_data)} è¡Œ Ã— {len(self.feature_names)} åˆ—")
            print(f"å¤„ç†åç‰¹å¾: {', '.join(self.feature_names)}")

            # éšè—åŠ è½½é®ç½©
            self.loading_frame.place_forget()

        except Exception as e:
            self.loading_frame.place_forget()
            messagebox.showerror("Error", f"Loading failed: {str(e)}")
            self.status_bar.config(text="Fails in loading data")
            print(f"Error during data loading: {str(e)}")

    def export_processed_data(self):
        """å¯¼å‡ºå¤„ç†åçš„æ•°æ®é›†"""
        if self.processed_data is None or self.feature_names is None:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯å¯¼å‡ºçš„å·²å¤„ç†æ•°æ®")
            return

        file_path = filedialog.asksaveasfilename(
            title="å¯¼å‡ºå¤„ç†åæ•°æ®",
            defaultextension=".xlsx",
            filetypes=[
                ("Excel file", "*.xlsx"),
                ("CSV file", "*.csv")
            ]
        )

        if not file_path:
            return

        try:
            # åˆ›å»ºåŒ…å«å¤„ç†åæ•°æ®çš„DataFrame
            processed_df = pd.DataFrame(self.processed_data, columns=self.feature_names)

            # æ·»åŠ æ ·å“IDåˆ—
            processed_df.insert(0, "Sample_ID", self.sample_ids)

            # å¯¼å‡º
            if file_path.endswith('.xlsx'):
                processed_df.to_excel(file_path, index=False)
            else:
                processed_df.to_csv(file_path, index=False)

            self.status_bar.config(text=f"å¤„ç†åæ•°æ®å·²æˆåŠŸå¯¼å‡º: {os.path.basename(file_path)}")
            messagebox.showinfo("æˆåŠŸ", "å·²æˆåŠŸå¯¼å‡ºå¤„ç†åçš„æ•°æ®é›†")

            # æ‰“å°å¤„ç†æ­¥éª¤ä¿¡æ¯
            print("æ•°æ®å¤„ç†æµç¨‹:")
            print("1. å¯¹å…ƒç´ æµ“åº¦ (Al, Sc, Ti, V, Fe, Ga, W, Sb, Zr, Hf, Nb, Ta, U) è¿›è¡ŒLOG10å˜æ¢ï¼Œä¿ç•™ç¼ºå¤±å€¼")
            print("2. ä½¿ç”¨RandomForestè¿›è¡Œ10æ¬¡æ’è¡¥ï¼Œå–å¹³å‡å€¼å¡«å……ç¼ºå¤±æ•°æ®")
            print("3. åˆ›å»ºæ´¾ç”Ÿç‰¹å¾: ZrHf, NbTa, SbW, FeAl, UHf, UZr")
            print(f"å¯¼å‡ºçš„å¤„ç†åæ•°æ®é›†åŒ…å« {len(processed_df)} è¡Œå’Œ {len(processed_df.columns)} åˆ—")
            print(f"ç‰¹å¾åˆ—è¡¨: {', '.join(processed_df.columns.tolist())}")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {str(e)}")

    def load_models(self):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            # æ˜¾ç¤ºåŠ è½½é®ç½©
            self.loading_frame.place(x=0, y=0, relwidth=1, relheight=1)
            self.root.update_idletasks()

            # ä½¿ç”¨çº¿ç¨‹åŠ è½½æ¨¡å‹ä»¥é˜²æ­¢UIå†»ç»“
            thread = threading.Thread(target=self._load_models_thread)
            thread.daemon = True
            thread.start()

            return True
        except Exception as e:
            self.loading_frame.place_forget()
            messagebox.showerror("é”™è¯¯", f"åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
            return False

    def _load_models_thread(self):
        """åœ¨çº¿ç¨‹ä¸­åŠ è½½æ¨¡å‹"""
        error_message = None

        try:
            # åŠ è½½æ¨¡å‹
            self.root.after(0, lambda: self.status_var.set("Loading RF model... (1/4)"))
            self.models["Random Forest"] = joblib.load(self.resource_path('best_rf_model.pkl'))

            self.root.after(0, lambda: self.status_var.set("Loading XGB model... (2/4)"))
            self.models["XGBoost"] = joblib.load(self.resource_path('best_xgb_model.pkl'))

            self.root.after(0, lambda: self.status_var.set("Loading TN model... (3/4)"))
            self.models["TabNet"] = joblib.load(self.resource_path('best_tabnet_model.pkl'))

            self.root.after(0, lambda: self.status_var.set("Loading Ensemble model... (4/4)"))
            self.models["Stacking"] = joblib.load(self.resource_path('best_ensem_model.pkl'))

            # è®¾ç½®æ¨¡å‹å·²åŠ è½½æ ‡å¿—
            self.models_loaded = True

            # æ›´æ–°çŠ¶æ€
            self.root.after(0, lambda: self.status_var.set("Model loaded"))

            # å¦‚æœæ˜¯ä»é¢„æµ‹å‡½æ•°è°ƒç”¨çš„ï¼Œç»§ç»­æ‰§è¡Œé¢„æµ‹
            if hasattr(self, '_continue_prediction') and self._continue_prediction:
                self.root.after(100, self._run_prediction_after_loading)
                self._continue_prediction = False

        except Exception as e:
            error_message = str(e)
            self.root.after(0, lambda: self.status_var.set("Failed to loading model"))
            self.models_loaded = False

        finally:
            # éšè—åŠ è½½é®ç½©
            self.root.after(0, self.loading_frame.place_forget)

            # å¦‚æœæœ‰é”™è¯¯ï¼Œæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
            if error_message:
                self.root.after(0, lambda: messagebox.showerror("Error", f"Failed to loading model: {error_message}"))

    def run_prediction(self):
        """æ‰§è¡Œé¢„æµ‹"""
        if self.processed_data is None:
            messagebox.showwarning("Warning", "Please load original data")
            return

        # å¦‚æœæ¨¡å‹æœªåŠ è½½ï¼Œå…ˆåŠ è½½æ¨¡å‹
        if not self.models_loaded:
            self.status_var.set("To load model...")
            self._continue_prediction = True
            if not self.load_models():
                return
        else:
            # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œç›´æ¥è¿è¡Œé¢„æµ‹
            self._run_prediction_after_loading()

    def _run_prediction_after_loading(self):
        """æ¨¡å‹åŠ è½½å®Œæˆåæ‰§è¡Œé¢„æµ‹"""
        try:
            # æ˜¾ç¤ºåŠ è½½é®ç½©
            self.loading_frame.place(x=0, y=0, relwidth=1, relheight=1)
            self.root.update_idletasks()

            # åœ¨çº¿ç¨‹ä¸­æ‰§è¡Œé¢„æµ‹
            thread = threading.Thread(target=self._predict_thread)
            thread.daemon = True
            thread.start()

        except Exception as e:
            self.loading_frame.place_forget()
            messagebox.showerror("Error", f"Error in predicition processes: {str(e)}")

    def _predict_thread(self):
        """åœ¨çº¿ç¨‹ä¸­æ‰§è¡Œé¢„æµ‹"""
        error_message = None

        try:
            # åˆ›å»ºä¸€ä¸ªæ–°çš„ç»“æœå­—å…¸
            results = {}

            # ä½¿ç”¨ä»æ•°æ®æ–‡ä»¶åŠ è½½çš„æ ·å“ID
            results["Sample_ID"] = self.sample_ids

            # è·å–ç±»åˆ«æ˜ å°„ï¼ˆå­—æ¯è¡¨ç¤ºï¼‰
            try:
                class_names = self.models["Random Forest"].classes_
                class_map = {i: chr(65+i) for i in range(len(class_names))}  # A, B, C...
            except:
                class_map = None

            # éšæœºæ£®æ—é¢„æµ‹
            self.root.after(0, lambda: self.status_bar.config(text="æ­£åœ¨ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹é¢„æµ‹..."))
            rf_pred = self.models["Random Forest"].predict(self.processed_data)
            rf_proba = self.models["Random Forest"].predict_proba(self.processed_data)

            if class_map:
                # å°†ç±»åˆ«æ•°å€¼è½¬æ¢ä¸ºå­—æ¯
                results["RF_Class"] = [class_map[p] for p in rf_pred]
            else:
                results["RF_Class"] = rf_pred

            results["RF_Confidence"] = np.max(rf_proba, axis=1)

            # XGBoosté¢„æµ‹
            self.root.after(0, lambda: self.status_bar.config(text="æ­£åœ¨ä½¿ç”¨XGBoostæ¨¡å‹é¢„æµ‹..."))
            xgb_pred = self.models["XGBoost"].predict(self.processed_data)
            xgb_proba = self.models["XGBoost"].predict_proba(self.processed_data)

            if class_map:
                results["XGB_Class"] = [class_map[p] for p in xgb_pred]
            else:
                results["XGB_Class"] = xgb_pred

            results["XGB_Confidence"] = np.max(xgb_proba, axis=1)

            # TabNeté¢„æµ‹
            self.root.after(0, lambda: self.status_bar.config(text="æ­£åœ¨ä½¿ç”¨TabNetæ¨¡å‹é¢„æµ‹..."))
            tabnet_pred = self.models["TabNet"].predict(self.processed_data)
            tabnet_proba = self.models["TabNet"].predict_proba(self.processed_data)

            if class_map:
                results["TabNet_Class"] = [class_map[p] for p in tabnet_pred]
            else:
                results["TabNet_Class"] = tabnet_pred

            results["TabNet_Confidence"] = np.max(tabnet_proba, axis=1)

            # é›†æˆæ¨¡å‹é¢„æµ‹
            self.root.after(0, lambda: self.status_bar.config(text="æ­£åœ¨ä½¿ç”¨é›†æˆæ¨¡å‹é¢„æµ‹..."))
            stack_pred = self.models["Stacking"].predict(self.processed_data)
            stack_proba = self.models["Stacking"].predict_proba(self.processed_data)

            if class_map:
                results["Stacking_Class"] = [class_map[p] for p in stack_pred]
            else:
                results["Stacking_Class"] = stack_pred

            results["Stacking_Confidence"] = np.max(stack_proba, axis=1)

            # åˆ›å»ºç»“æœDataFrame
            self.prediction_results = pd.DataFrame(results)

            # å°†åŸå§‹æ•°æ®ç‰¹å¾æ·»åŠ åˆ°ç»“æœä¸­ï¼ˆç”¨äºå¯¼å‡ºï¼‰
            # é¦–å…ˆæ·»åŠ åŸå§‹å…ƒç´ ç‰¹å¾ï¼ˆç»è¿‡LOG10å’Œæ’è¡¥ï¼‰
            element_cols = [col for col in self.element_features if col in self.feature_names]
            for i, col in enumerate(element_cols):
                col_index = self.feature_names.index(col)
                self.prediction_results[col] = self.processed_data[:, col_index]

            # ç„¶åæ·»åŠ æ´¾ç”Ÿç‰¹å¾
            derived_cols = [col for col in self.derived_features if col in self.feature_names]
            for i, col in enumerate(derived_cols):
                col_index = self.feature_names.index(col)
                self.prediction_results[col] = self.processed_data[:, col_index]

            # æ›´æ–°UIæ˜¾ç¤ºç»“æœ
            self.root.after(0, self.display_results)
            self.root.after(0, lambda: self.status_bar.config(text="Prediction Finished"))

        except Exception as e:
            error_message = str(e)
            self.root.after(0, lambda: self.status_bar.config(text="Prediction Failed"))
            print(f"é¢„æµ‹é”™è¯¯: {str(e)}")

        finally:
            # éšè—åŠ è½½é®ç½©
            self.root.after(0, self.loading_frame.place_forget)

            # å¦‚æœæœ‰é”™è¯¯ï¼Œæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
            if error_message:
                self.root.after(0, lambda: messagebox.showerror("Error", f"Prediction Failed: {error_message}"))

    def display_results(self):
        """åœ¨è¡¨æ ¼ä¸­æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
        if self.prediction_results is None:
            return

        # æ¸…é™¤ç°æœ‰æ•°æ®
        for item in self.result_tree.get_children():
            self.result_tree.delete(item)

        # è®¾ç½®è¦æ˜¾ç¤ºçš„åˆ—
        display_cols = [
            "Sample_ID",
            "RF_Class", "RF_Confidence",
            "XGB_Class", "XGB_Confidence",
            "TabNet_Class", "TabNet_Confidence",
            "Stacking_Class", "Stacking_Confidence"
        ]

        # é…ç½®æ ‘å½¢è§†å›¾
        self.result_tree['columns'] = display_cols
        self.result_tree['show'] = 'headings'

        # è®¾ç½®åˆ—æ ‡é¢˜
        column_labels = {
            "Sample_ID": "Sample ID",
            "RF_Class": "RF Class",
            "RF_Confidence": "RF Prob",
            "XGB_Class": "XGB Class",
            "XGB_Confidence": "XGB Prob",
            "TabNet_Class": "TabNet Class",
            "TabNet_Confidence": "TabNet Prob",
            "Stacking_Class": "Ensemble Class",
            "Stacking_Confidence": "Ensemble Prob"
        }

        for col in display_cols:
            self.result_tree.heading(col, text=column_labels.get(col, col))

            # è®¾ç½®åˆ—å®½
            if col == "Sample_ID":
                self.result_tree.column(col, width=100, anchor=tk.W)  # è°ƒæ•´å®½åº¦å¹¶å·¦å¯¹é½
            elif "Confidence" in col:
                self.result_tree.column(col, width=80, anchor=tk.CENTER)
            else:
                self.result_tree.column(col, width=80, anchor=tk.CENTER)

        # æ’å…¥æ•°æ®
        for i, row in self.prediction_results.iterrows():
            values = []
            for col in display_cols:
                if "Confidence" in col:
                    # æ ¼å¼åŒ–ç½®ä¿¡åº¦ä¸º XX.XX%
                    values.append(f"{row[col]*100:.2f}%")
                else:
                    values.append(str(row[col]))

            self.result_tree.insert('', 'end', values=values)

        # æ˜¾ç¤ºè®°å½•æ•°é‡
        print(f"æ˜¾ç¤ºé¢„æµ‹ç»“æœ: {len(self.prediction_results)} æ¡è®°å½•")

    def export_results(self):
        """å¯¼å‡ºé¢„æµ‹ç»“æœ"""
        if self.prediction_results is None:
            messagebox.showwarning("Warning", "No results for exporting")
            return

        file_path = filedialog.asksaveasfilename(
            title="Export Prediction",
            defaultextension=".xlsx",
            filetypes=[
                ("Excel file", "*.xlsx"),
                ("CSV file", "*.csv")
            ]
        )

        if not file_path:
            return

        try:
            # åˆ›å»ºå¯¼å‡ºæ•°æ®çš„å‰¯æœ¬
            export_df = self.prediction_results.copy()

            # å°†ç½®ä¿¡åº¦åˆ—è½¬æ¢ä¸ºç™¾åˆ†æ¯”æ ¼å¼
            for col in export_df.columns:
                if "Confidence" in col:
                    export_df[col] = export_df[col].apply(lambda x: f"{x*100:.2f}%")

            if file_path.endswith('.xlsx'):
                export_df.to_excel(file_path, index=False)
            else:
                export_df.to_csv(file_path, index=False)

            self.status_bar.config(text=f"Exported successfully: {os.path.basename(file_path)}")
            messagebox.showinfo("Success", "Successful to export")

        except Exception as e:
            messagebox.showerror("Error", f"Failed to export: {str(e)}")

    def run(self):
        """è¿è¡Œåº”ç”¨ç¨‹åº"""
        self.root.mainloop()

if __name__ == "__main__":
    app = ModelPredictorApp()
    app.run()